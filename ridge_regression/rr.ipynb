{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Jul  6 16:00:55 2020\n",
    "\n",
    "@author: haolinl\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import scipy.io\n",
    "\n",
    "from sklearn import linear_model\n",
    "from torchvision.transforms import Compose, ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"head_and_neck\" # One of \"head_and_neck\", \"kidney\", and \"aorta\".\n",
    "alpha = 0.001 # Weight applied to the regularizaion term. \n",
    "deformation_scalar = 100 # Scale back to real dimensions by this number. Inherited from the main code. Default: 100. Do not need to change. \n",
    "gt_mode = \"restored\" # Either \"reconstructed\" or \"restored\". Do not need to change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# HELP FUNCTIONS. \n",
    "\n",
    "def get_non_zero_indices_list(fix_indices_list, nDOF):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        fix_indices_list (_type_): Indexing from 1. \n",
    "        nDOF (_type_): _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    fix_indices_list = [item-1 for item in fix_indices_list] # Return to zero-indexing. \n",
    "    non_zero_indices_list = []\n",
    "    \n",
    "    for i in range(int(nDOF/3)): # Iterate within the range of node_num. \n",
    "        if i not in fix_indices_list: \n",
    "            non_zero_indices_list.append(i*3)\n",
    "            non_zero_indices_list.append(i*3+1)\n",
    "            non_zero_indices_list.append(i*3+2)\n",
    "            \n",
    "    return non_zero_indices_list # Index from 0. Dim: (nDOF-nFix*3) * 1. \n",
    "\n",
    "\n",
    "def matrixExpand(data_matrix, nDOF, non_zero_indices_list):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        data_matrix (_type_): Shape: nFeature * nSample. \n",
    "        nDOF (_type_): _description_\n",
    "        non_zero_indices_list (_type_): _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    data_expanded = np.zeros(shape=(nDOF, data_matrix.shape[1]), dtype=complex)\n",
    "\n",
    "    for i, index in enumerate(non_zero_indices_list):\n",
    "        data_expanded[index,:] = data_matrix[i,:]\n",
    "    \n",
    "    return np.real(data_expanded)\n",
    "\n",
    "\n",
    "def dataReconstruction_Autoencoder(encoder_model, latent_mat, nDOF, \n",
    "                                   non_zero_indices_list, device, \n",
    "                                   dtype=torch.float, transform=Compose([ToTensor()])):\n",
    "    \"\"\"\n",
    "    latent_mat: nSample * nFeature. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Transform weights back to original vector space (decoding). \n",
    "    encoder_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(latent_mat.shape[0]):\n",
    "            latent = latent_mat[i,:]\n",
    "            data_temp = encoder_model.decoder(transform(latent.reshape(1,-1)).to(dtype).to(device))\n",
    "            data_temp = data_temp.cpu().data.numpy().astype(float).reshape(-1,1)\n",
    "            \n",
    "            if i == 0: data_reconstruct_mat = copy.deepcopy(data_temp)\n",
    "            else: data_reconstruct_mat = np.hstack((data_reconstruct_mat, \n",
    "                                                    copy.deepcopy(data_temp))) # Shape: (nDOF-nFix*3) * nSample. \n",
    "    \n",
    "    return matrixExpand(data_reconstruct_mat, nDOF, non_zero_indices_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == \"head_and_neck\":\n",
    "    working_directory = \"head_and_neck\"\n",
    "    FM_indices_array = np.array([4,96,431,752,1144]).reshape(-1) # Index from 0. Do not need to change. \n",
    "    nDOF, fix_indices_list = 3474, [761, 1000, 1158] # Index from 1. Do not need to change. \n",
    "    non_zero_indices_list = get_non_zero_indices_list(fix_indices_list, nDOF) # Index from 0. Dim: (nDOF-nFix*3) * 1.\n",
    "\n",
    "elif model_name == \"kidney\":\n",
    "    working_directory = \"kidney\"\n",
    "    FM_indices_array = np.array([9,235,327,350,475]).reshape(-1) # Index from 0. Do not need to change. \n",
    "    nDOF, fix_indices_list = 3372, [2, 453, 745] # Index from 1.Do not need to change. \n",
    "    non_zero_indices_list = get_non_zero_indices_list(fix_indices_list, nDOF) # Index from 0. Dim: (nDOF-nFix*3) * 1.\n",
    "\n",
    "elif model_name == \"aorta\":\n",
    "    working_directory = \"aorta\"\n",
    "    FM_indices_array = np.array([129,381,429,467,475,484,662,798,1123,1151]).reshape(-1) # Index from 0. Do not need to change. \n",
    "    nDOF, fix_indices_list = 3654, [1148, 1156, 1169] # Index from 1. Do not need to change. \n",
    "    non_zero_indices_list = get_non_zero_indices_list(fix_indices_list, nDOF) # Index from 0. Dim: (nDOF-nFix*3) * 1.\n",
    "    \n",
    "else: raise ValueError(\"Illegal 'model_name' input. \")\n",
    "\n",
    "deform_dataset_filepath = os.path.join(working_directory, \"groundtruths_list.npy\")\n",
    "latent_encoding_filepath = os.path.join(working_directory, \"latent_list.npy\")\n",
    "train_set_indices_filepath = os.path.join(working_directory, \"train_set_ind_array.npy\")\n",
    "test_set_indices_filepath = os.path.join(working_directory, \"test_set_ind_array.npy\")\n",
    "AE_model_filepath = os.path.join(working_directory, \"model_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing. \n",
    "\n",
    "deform_matrix = np.load(deform_dataset_filepath) # Dim: nSample * (nDOF-nFix*3).\n",
    "\n",
    "FM_disp_matrix = np.zeros(shape=(deform_matrix.shape[0], int(len(FM_indices_array)*3))) # Size: nSample * nFM_disp.\n",
    "for i, index in enumerate(FM_indices_array):\n",
    "    FM_disp_matrix[:,i*3:(i+1)*3] = deform_matrix[:,int(index*3):int((index+1)*3)]\n",
    "\n",
    "latent_matrix = np.load(latent_encoding_filepath) # Dim: nSample * nFeature. \n",
    "train_set_indices_arr = np.load(train_set_indices_filepath).astype(int).reshape(-1)\n",
    "test_set_indices_arr = np.load(test_set_indices_filepath).astype(int).reshape(-1)\n",
    "\n",
    "train_x_mat = FM_disp_matrix[train_set_indices_arr]\n",
    "train_y_mat = latent_matrix[train_set_indices_arr]\n",
    "test_x_mat = FM_disp_matrix[test_set_indices_arr]\n",
    "test_y_mat = latent_matrix[test_set_indices_arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge regression model optimizing. \n",
    "\n",
    "rr_model = linear_model.Ridge(alpha=alpha)\n",
    "rr_model.fit(train_x_mat, train_y_mat) # Ridge regression model training. \n",
    "\n",
    "test_pred_mat = rr_model.predict(test_x_mat) # RR prediction. \n",
    "train_pred_mat = rr_model.predict(train_x_mat) # RR prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AE reconstruction. \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ae_model = torch.load(AE_model_filepath).to(device)\n",
    "\n",
    "if gt_mode == \"reconstructed\":\n",
    "    data_reconstruct_test_y = dataReconstruction_Autoencoder(ae_model, test_y_mat, \n",
    "                                                             nDOF, non_zero_indices_list, \n",
    "                                                             device) # Shape: nDOF * nSample. Reconstruct via grountruth latents. \n",
    "    data_reconstruct_train_y = dataReconstruction_Autoencoder(ae_model, train_y_mat, \n",
    "                                                              nDOF, non_zero_indices_list, \n",
    "                                                              device) # Shape: nDOF * nSample. Reconstruct via grountruth latents.\n",
    "elif gt_mode == \"restored\": \n",
    "    data_reconstruct_test_y = matrixExpand(deform_matrix[test_set_indices_arr].T, \n",
    "                                           nDOF, non_zero_indices_list) # Shape: nDOF * nSample. Restore from grountruth deformation.\n",
    "    data_reconstruct_train_y = matrixExpand(deform_matrix[train_set_indices_arr].T, \n",
    "                                            nDOF, non_zero_indices_list) # Shape: nDOF * nSample. Restore from grountruth deformation.\n",
    "else: raise ValueError(\"Illegal 'gt_mode' input. \")\n",
    "\n",
    "data_reconstruct_test_predict = dataReconstruction_Autoencoder(ae_model, test_pred_mat, \n",
    "                                                               nDOF, non_zero_indices_list, \n",
    "                                                               device) # Shape: nDOF * nSample. \n",
    "\n",
    "data_reconstruct_train_predict = dataReconstruction_Autoencoder(ae_model, train_pred_mat, \n",
    "                                                                nDOF, non_zero_indices_list, \n",
    "                                                                device) # Shape: nDOF * nSample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results as .mat files. \n",
    "\n",
    "mdict = {\"model_name\": model_name, \"gt_mode\": gt_mode,\n",
    "         \"FM_indices\": FM_indices_array.astype(int).reshape(-1,1)+1,\n",
    "         \"fix_node_list\": fix_indices_list, \"nDOF\": nDOF, \n",
    "         \"RR_alpha\": alpha, \"deformation_scalar\": deformation_scalar,\n",
    "         \"test_deformation_label\": data_reconstruct_test_y/deformation_scalar, # Groundtruth on test dataset. \n",
    "         \"test_deformation_reconstruct\": data_reconstruct_test_predict/deformation_scalar, # RR reconstruction on test dataset. \n",
    "         \"train_deformation_label\": data_reconstruct_train_y/deformation_scalar, # Groundtruth on training dataset. \n",
    "         \"train_deformation_reconstruct\": data_reconstruct_train_predict/deformation_scalar} # RR reconstruction on training dataset.\n",
    "\n",
    "mat_save_path = os.path.join(working_directory, \"RR_benchmark_result_alpha_{}.mat\".format(alpha))\n",
    "scipy.io.savemat(mat_save_path, mdict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7c4f131a244ba5653061a21302de6d61a3d727882dbca135c6571cb8fa95b9f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
